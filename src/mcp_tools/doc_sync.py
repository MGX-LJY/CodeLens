"""
MCP doc_sync ç»Ÿä¸€å·¥å…·å®ç°
æ™ºèƒ½æ–‡æ¡£åŒæ­¥å·¥å…· - åˆå¹¶ doc_update_init å’Œ doc_update åŠŸèƒ½
è‡ªåŠ¨æ£€æµ‹é¡¹ç›®çŠ¶æ€ï¼Œæ‰§è¡Œåˆå§‹åŒ–æˆ–æ›´æ–°æ£€æµ‹ï¼Œå¹¶è®°å½•å®Œæ•´å˜æ›´å†å²
"""
import sys
import os
import json
import hashlib
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List, Tuple

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°pathä»¥å¯¼å…¥å…¶ä»–æ¨¡å—
project_root = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
sys.path.insert(0, project_root)

from src.logging import get_logger


class DocSyncTool:
    """MCP doc_sync ç»Ÿä¸€å·¥å…·ç±» - æ™ºèƒ½æ–‡æ¡£åŒæ­¥"""

    def __init__(self):
        self.tool_name = "doc_sync"
        self.description = "æ™ºèƒ½æ–‡æ¡£åŒæ­¥å·¥å…· - è‡ªåŠ¨æ£€æµ‹å¹¶å¤„ç†é¡¹ç›®æ–‡ä»¶å˜æ›´"
        self.logger = get_logger(component="DocSyncTool", operation="init")
        self.logger.info("DocSyncTool åˆå§‹åŒ–å®Œæˆ")

    def get_tool_definition(self) -> Dict[str, Any]:
        """è·å–MCPå·¥å…·å®šä¹‰"""
        return {
            "name": self.tool_name,
            "description": self.description,
            "inputSchema": {
                "type": "object",
                "properties": {
                    "project_path": {
                        "type": "string",
                        "description": "é¡¹ç›®æ ¹è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨å½“å‰å·¥ä½œç›®å½•ï¼‰"
                    },
                    "mode": {
                        "type": "string",
                        "enum": ["auto", "init", "update", "status"],
                        "description": "æ“ä½œæ¨¡å¼ï¼šauto=æ™ºèƒ½æ£€æµ‹ï¼Œinit=å¼ºåˆ¶åˆå§‹åŒ–ï¼Œupdate=å¼ºåˆ¶æ›´æ–°ï¼Œstatus=æŸ¥çœ‹çŠ¶æ€"
                    },
                    "record_changes": {
                        "type": "boolean",
                        "description": "æ˜¯å¦è®°å½•å˜æ›´å†å²ï¼ˆé»˜è®¤trueï¼‰"
                    }
                },
                "required": []
            }
        }

    def execute(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œdoc_syncå·¥å…·"""
        self.logger.info("å¼€å§‹doc_syncæ“ä½œ", {"arguments": arguments})

        try:
            # å‚æ•°è§£æ
            project_path = arguments.get("project_path")
            if not project_path:
                project_path = os.getcwd()
                self.logger.info("æœªæä¾›project_pathï¼Œä½¿ç”¨å½“å‰å·¥ä½œç›®å½•", {
                    "current_working_directory": project_path
                })

            project_path = Path(project_path)
            if not project_path.exists():
                error_msg = f"Project path does not exist: {project_path}"
                self.logger.error(error_msg)
                return self._error_response(error_msg)

            if not project_path.is_dir():
                error_msg = f"Project path is not a directory: {project_path}"
                self.logger.error(error_msg)
                return self._error_response(error_msg)

            mode = arguments.get("mode", "auto")
            record_changes = arguments.get("record_changes", True)

            # ç¡®ä¿.codelensç›®å½•å­˜åœ¨
            codelens_dir = project_path / ".codelens"
            codelens_dir.mkdir(exist_ok=True)

            # å¤„ç†ä¸åŒæ¨¡å¼
            if mode == "status":
                result = self._get_status(project_path)
            elif mode == "auto":
                detected_mode = self._detect_mode(project_path)
                self.logger.info(f"æ™ºèƒ½æ£€æµ‹æ¨¡å¼: {detected_mode}")
                if detected_mode == "init":
                    result = self._execute_init(project_path, record_changes)
                else:
                    result = self._execute_update(project_path, record_changes)
            elif mode == "init":
                result = self._execute_init(project_path, record_changes)
            elif mode == "update":
                result = self._execute_update(project_path, record_changes)
            else:
                error_msg = f"ä¸æ”¯æŒçš„æ¨¡å¼: {mode}"
                self.logger.error(error_msg)
                return self._error_response(error_msg)

            self.logger.info("doc_syncæ“ä½œå®Œæˆ", {
                "project_path": str(project_path),
                "mode": mode,
                "result_type": result.get("data", {}).get("operation", "unknown")
            })

            return result

        except Exception as e:
            self.logger.error(f"doc_syncæ“ä½œå¤±è´¥: {arguments.get('project_path')}, é”™è¯¯: {str(e)}", exc_info=e)
            return self._error_response(f"æ“ä½œå¤±è´¥: {str(e)}")

    def _detect_mode(self, project_path: Path) -> str:
        """æ™ºèƒ½æ£€æµ‹åº”è¯¥ä½¿ç”¨initè¿˜æ˜¯updateæ¨¡å¼"""
        fingerprints_file = project_path / ".codelens" / "file_fingerprints.json"
        
        if not fingerprints_file.exists():
            self.logger.info("æœªæ‰¾åˆ°æŒ‡çº¹æ–‡ä»¶ï¼Œå°†æ‰§è¡Œåˆå§‹åŒ–")
            return "init"
        
        # æ£€æŸ¥æŒ‡çº¹æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ
        try:
            with open(fingerprints_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            if "files" in data and isinstance(data["files"], dict) and len(data["files"]) > 0:
                self.logger.info(f"å‘ç°æœ‰æ•ˆæŒ‡çº¹æ–‡ä»¶ï¼ŒåŒ…å«{len(data['files'])}ä¸ªæ–‡ä»¶è®°å½•ï¼Œå°†æ‰§è¡Œæ›´æ–°æ£€æµ‹")
                return "update"
        except (json.JSONDecodeError, KeyError) as e:
            self.logger.warning(f"æŒ‡çº¹æ–‡ä»¶æŸå: {e}ï¼Œå°†é‡æ–°åˆå§‹åŒ–")
        
        return "init"

    def _execute_init(self, project_path: Path, record_changes: bool = True) -> Dict[str, Any]:
        """æ‰§è¡Œåˆå§‹åŒ–æ“ä½œ"""
        self.logger.info("å¼€å§‹æ‰§è¡Œåˆå§‹åŒ–æ“ä½œ")
        
        # æ‰«æé¡¹ç›®æ–‡ä»¶
        current_files = self._scan_project_files(project_path)
        
        # åˆ›å»ºæŒ‡çº¹æ–‡ä»¶
        fingerprints = {
            "created_at": datetime.now().isoformat(),
            "last_updated": datetime.now().isoformat(),
            "files": current_files
        }
        
        fingerprints_file = project_path / ".codelens" / "file_fingerprints.json"
        with open(fingerprints_file, 'w', encoding='utf-8') as f:
            json.dump(fingerprints, f, indent=2, ensure_ascii=False)
        
        # è®°å½•å˜æ›´å†å²
        change_info = {
            "operation": "init",
            "files_count": len(current_files),
            "summary": f"åˆå§‹åŒ–é¡¹ç›®æŒ‡çº¹åŸºç‚¹ï¼Œè®°å½•{len(current_files)}ä¸ªä»£ç æ–‡ä»¶"
        }
        
        if record_changes:
            self._record_change_history(project_path, change_info)
        
        self.logger.info(f"åˆå§‹åŒ–å®Œæˆï¼Œå…±è®°å½•{len(current_files)}ä¸ªæ–‡ä»¶")
        
        return self._success_response({
            "operation": "init",
            "files_count": len(current_files),
            "message": f"âœ… åˆå§‹åŒ–å®Œæˆï¼Œå·²è®°å½• {len(current_files)} ä¸ªæ–‡ä»¶çš„æŒ‡çº¹åŸºç‚¹",
            "fingerprints_file": str(fingerprints_file)
        })

    def _execute_update(self, project_path: Path, record_changes: bool = True) -> Dict[str, Any]:
        """æ‰§è¡Œæ›´æ–°æ£€æµ‹æ“ä½œ"""
        self.logger.info("å¼€å§‹æ‰§è¡Œæ›´æ–°æ£€æµ‹æ“ä½œ")
        
        fingerprints_file = project_path / ".codelens" / "file_fingerprints.json"
        
        if not fingerprints_file.exists():
            return self._error_response("æŒ‡çº¹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆæ‰§è¡Œåˆå§‹åŒ–")
        
        # åŠ è½½æ—§æŒ‡çº¹
        with open(fingerprints_file, 'r', encoding='utf-8') as f:
            old_fingerprints = json.load(f)
        
        old_files = old_fingerprints.get("files", {})
        
        # æ‰«æå½“å‰æ–‡ä»¶çŠ¶æ€
        current_files = self._scan_project_files(project_path)
        
        # æ£€æµ‹å˜åŒ–
        changed_files, new_files, deleted_files = self._compare_files(old_files, current_files)
        
        # ç”Ÿæˆæ›´æ–°å»ºè®®
        suggestion = self._generate_suggestion(changed_files, new_files, deleted_files)
        
        # æ›´æ–°æŒ‡çº¹æ–‡ä»¶
        new_fingerprints = {
            "created_at": old_fingerprints.get("created_at"),
            "last_updated": datetime.now().isoformat(),
            "files": current_files
        }
        
        with open(fingerprints_file, 'w', encoding='utf-8') as f:
            json.dump(new_fingerprints, f, indent=2, ensure_ascii=False)
        
        # è®°å½•å˜æ›´å†å²
        has_changes = bool(changed_files or new_files or deleted_files)
        change_info = {
            "operation": "update",
            "has_changes": has_changes,
            "files_count": len(current_files),
            "changes": {
                "modified": changed_files,
                "added": new_files,
                "deleted": deleted_files
            }
        }
        
        if has_changes:
            change_summary = []
            if changed_files:
                change_summary.append(f"ä¿®æ”¹{len(changed_files)}ä¸ªæ–‡ä»¶")
            if new_files:
                change_summary.append(f"æ–°å¢{len(new_files)}ä¸ªæ–‡ä»¶")
            if deleted_files:
                change_summary.append(f"åˆ é™¤{len(deleted_files)}ä¸ªæ–‡ä»¶")
            change_info["summary"] = f"æ£€æµ‹åˆ°å˜æ›´ï¼š{', '.join(change_summary)}"
        else:
            change_info["summary"] = "æœªæ£€æµ‹åˆ°æ–‡ä»¶å˜æ›´"
        
        if record_changes:
            self._record_change_history(project_path, change_info)
        
        self.logger.info(f"æ›´æ–°æ£€æµ‹å®Œæˆï¼Œå˜æ›´ç»Ÿè®¡: ä¿®æ”¹{len(changed_files)}, æ–°å¢{len(new_files)}, åˆ é™¤{len(deleted_files)}")
        
        return self._success_response({
            "operation": "update",
            "has_changes": has_changes,
            "files_count": len(current_files),
            "changes": {
                "modified": changed_files,
                "added": new_files,
                "deleted": deleted_files
            },
            "suggestion": suggestion,
            "message": f"âœ… æ›´æ–°æ£€æµ‹å®Œæˆï¼Œå…±æ£€æµ‹ {len(current_files)} ä¸ªæ–‡ä»¶"
        })

    def _get_status(self, project_path: Path) -> Dict[str, Any]:
        """è·å–å½“å‰çŠ¶æ€ä¿¡æ¯"""
        self.logger.info("è·å–é¡¹ç›®çŠ¶æ€ä¿¡æ¯")
        
        codelens_dir = project_path / ".codelens"
        fingerprints_file = codelens_dir / "file_fingerprints.json"
        history_file = codelens_dir / "change_history.json"
        
        status_info = {
            "project_path": str(project_path),
            "has_fingerprints": fingerprints_file.exists(),
            "has_history": history_file.exists()
        }
        
        # è¯»å–æŒ‡çº¹ä¿¡æ¯
        if fingerprints_file.exists():
            try:
                with open(fingerprints_file, 'r', encoding='utf-8') as f:
                    fingerprints = json.load(f)
                status_info.update({
                    "fingerprints_created": fingerprints.get("created_at"),
                    "fingerprints_updated": fingerprints.get("last_updated"),
                    "tracked_files": len(fingerprints.get("files", {}))
                })
            except Exception as e:
                status_info["fingerprints_error"] = str(e)
        
        # è¯»å–å†å²ä¿¡æ¯
        if history_file.exists():
            try:
                with open(history_file, 'r', encoding='utf-8') as f:
                    history = json.load(f)
                status_info.update({
                    "history_created": history.get("created_at"),
                    "history_updated": history.get("last_updated"),
                    "total_operations": history.get("total_operations", 0),
                    "last_operation": history.get("history", [])[-1] if history.get("history") else None
                })
            except Exception as e:
                status_info["history_error"] = str(e)
        
        return self._success_response({
            "operation": "status",
            "status": status_info,
            "message": "ğŸ“Š é¡¹ç›®çŠ¶æ€ä¿¡æ¯è·å–å®Œæˆ"
        })

    def _scan_project_files(self, project_path: Path) -> Dict[str, Dict[str, Any]]:
        """æ‰«æé¡¹ç›®æ–‡ä»¶ - é‡ç”¨ç°æœ‰é€»è¾‘"""
        current_files = {}
        
        # å®šä¹‰éœ€è¦å¿½ç•¥çš„ç›®å½•
        ignore_dirs = {
            '.git', '__pycache__', '.pytest_cache', 'node_modules', 
            '.idea', '.vscode', 'venv', 'env', '.env', 'dist', 'build',
            'docs',  # æ’é™¤æ–‡æ¡£ç›®å½•
            '.codelens'  # æ’é™¤codelenså·¥ä½œç›®å½•
        }
        
        # å®šä¹‰éœ€è¦å¿½ç•¥çš„æ–‡ä»¶æ‰©å±•åï¼ˆæ–‡æ¡£æ–‡ä»¶ï¼‰
        ignore_extensions = {
            '.md', '.txt', '.rst', '.doc', '.docx', '.pdf',
            '.log', '.tmp', '.temp', '.cache', '.bak',
            '.pyc', '.pyo', '.pyd', '__pycache__'
        }
        
        # å®šä¹‰éœ€è¦æ£€æµ‹çš„æ–‡ä»¶æ‰©å±•åï¼ˆä»£ç æ–‡ä»¶ï¼‰
        code_extensions = {
            '.py', '.js', '.jsx', '.ts', '.tsx', '.json', '.yaml', '.yml',
            '.toml', '.cfg', '.ini', '.conf', '.sh', '.bat', '.ps1',
            '.html', '.css', '.scss', '.less', '.vue', '.go', '.rs',
            '.java', '.kt', '.cpp', '.c', '.h', '.hpp', '.cs', '.php',
            '.rb', '.swift', '.dart', '.sql', '.r', '.m', '.scala'
        }
        
        # éå†æ•´ä¸ªé¡¹ç›®ç›®å½•
        for file_path in project_path.rglob("*"):
            if file_path.is_file():
                try:
                    # æ£€æŸ¥æ˜¯å¦åœ¨å¿½ç•¥çš„ç›®å½•ä¸­
                    if any(ignore_dir in file_path.parts for ignore_dir in ignore_dirs):
                        continue
                    
                    # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
                    file_suffix = file_path.suffix.lower()
                    
                    # è·³è¿‡æ–‡æ¡£æ–‡ä»¶å’Œå…¶ä»–å¿½ç•¥çš„æ–‡ä»¶
                    if file_suffix in ignore_extensions:
                        continue
                    
                    # åªå¤„ç†ä»£ç æ–‡ä»¶æˆ–è€…æ— æ‰©å±•åçš„é‡è¦æ–‡ä»¶
                    if file_suffix not in code_extensions and file_suffix != '':
                        # æ£€æŸ¥æ˜¯å¦æ˜¯é‡è¦çš„æ— æ‰©å±•åæ–‡ä»¶
                        important_files = {
                            'Dockerfile', 'Makefile', 'requirements.txt', 
                            'package.json', 'Cargo.toml', 'go.mod', 'pom.xml'
                        }
                        if file_path.name not in important_files:
                            continue
                    
                    # è¯»å–æ–‡ä»¶å†…å®¹å¹¶è®¡ç®—å“ˆå¸Œ
                    content = file_path.read_text(encoding='utf-8')
                    file_hash = hashlib.md5(content.encode()).hexdigest()
                    
                    relative_path = str(file_path.relative_to(project_path))
                    current_files[relative_path] = {
                        "hash": file_hash,
                        "size": file_path.stat().st_size,
                        "modified_time": datetime.fromtimestamp(file_path.stat().st_mtime).isoformat()
                    }
                    
                except Exception as e:
                    self.logger.warning(f"è·³è¿‡æ–‡ä»¶ {file_path}: {e}")
        
        self.logger.info(f"æ‰«æå®Œæˆï¼Œå…±æ£€æµ‹åˆ° {len(current_files)} ä¸ªä»£ç æ–‡ä»¶")
        return current_files

    def _compare_files(self, old_files: Dict[str, Dict[str, Any]], 
                      current_files: Dict[str, Dict[str, Any]]) -> Tuple[List[str], List[str], List[str]]:
        """å¯¹æ¯”æ–‡ä»¶å˜åŒ–"""
        changed_files = []
        new_files = []
        deleted_files = []
        
        for file_path, current_info in current_files.items():
            if file_path in old_files:
                if current_info["hash"] != old_files[file_path]["hash"]:
                    changed_files.append(file_path)
            else:
                new_files.append(file_path)
        
        for file_path in old_files:
            if file_path not in current_files:
                deleted_files.append(file_path)
        
        return changed_files, new_files, deleted_files

    def _generate_suggestion(self, changed_files: List[str], new_files: List[str], 
                           deleted_files: List[str]) -> str:
        """ç”Ÿæˆæ›´æ–°å»ºè®®æç¤ºè¯"""
        if not changed_files and not new_files and not deleted_files:
            return "âœ… æ²¡æœ‰æ£€æµ‹åˆ°æ–‡ä»¶å˜åŒ–ï¼Œæ— éœ€æ›´æ–°æ–‡æ¡£ã€‚"
        
        suggestion = "ğŸ“ æ£€æµ‹åˆ°ä»¥ä¸‹æ–‡ä»¶å˜åŒ–ï¼Œå»ºè®®æ›´æ–°ç›¸å…³æ–‡æ¡£ï¼š\n\n"
        
        if changed_files:
            suggestion += "ğŸ”„ **å·²ä¿®æ”¹çš„æ–‡ä»¶ï¼š**\n"
            for file in changed_files:
                suggestion += f"- {file}\n"
            suggestion += "\n"
        
        if new_files:
            suggestion += "âœ¨ **æ–°å¢çš„æ–‡ä»¶ï¼š**\n"
            for file in new_files:
                suggestion += f"- {file}\n"
            suggestion += "\n"
        
        if deleted_files:
            suggestion += "ğŸ—‘ï¸ **å·²åˆ é™¤çš„æ–‡ä»¶ï¼š**\n"
            for file in deleted_files:
                suggestion += f"- {file}\n"
            suggestion += "\n"
        
        suggestion += "ğŸ’¡ **å»ºè®®æ“ä½œï¼š**\n"
        suggestion += "1. æ£€æŸ¥å¹¶æ›´æ–°è¿™äº›æ–‡ä»¶å¯¹åº”çš„æ–‡æ¡£å†…å®¹\n"
        suggestion += "2. æ›´æ–°é¡¹ç›®READMEä¸­çš„ç›¸å…³è¯´æ˜\n"
        suggestion += "3. å¦‚æœ‰æ¶æ„å˜æ›´ï¼Œè¯·æ›´æ–°æ¶æ„æ–‡æ¡£\n"
        
        return suggestion

    def _record_change_history(self, project_path: Path, change_info: Dict[str, Any]):
        """è®°å½•å˜æ›´å†å²"""
        history_file = project_path / ".codelens" / "change_history.json"
        last_change_file = project_path / ".codelens" / "last_change.json"
        
        # ç”Ÿæˆå˜æ›´è®°å½•
        change_record = {
            "id": f"change_{int(datetime.now().timestamp() * 1000)}",
            "timestamp": datetime.now().isoformat(),
            **change_info
        }
        
        # è¯»å–æˆ–åˆ›å»ºå†å²è®°å½•
        if history_file.exists():
            try:
                with open(history_file, 'r', encoding='utf-8') as f:
                    history = json.load(f)
            except Exception:
                history = self._create_empty_history()
        else:
            history = self._create_empty_history()
        
        # æ·»åŠ æ–°è®°å½•
        history["history"].append(change_record)
        history["last_updated"] = datetime.now().isoformat()
        history["total_operations"] = len(history["history"])
        
        # ä¿å­˜å†å²è®°å½•
        with open(history_file, 'w', encoding='utf-8') as f:
            json.dump(history, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜æœ€æ–°å˜æ›´
        with open(last_change_file, 'w', encoding='utf-8') as f:
            json.dump(change_record, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"å˜æ›´å†å²å·²è®°å½•: {change_record['id']}")

    def _create_empty_history(self) -> Dict[str, Any]:
        """åˆ›å»ºç©ºçš„å†å²è®°å½•ç»“æ„"""
        return {
            "created_at": datetime.now().isoformat(),
            "last_updated": datetime.now().isoformat(),
            "total_operations": 0,
            "history": []
        }

    def _success_response(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """æˆåŠŸå“åº”"""
        return {
            "success": True,
            "tool": self.tool_name,
            "data": data
        }

    def _error_response(self, message: str) -> Dict[str, Any]:
        """é”™è¯¯å“åº”"""
        self.logger.error("ç”Ÿæˆé”™è¯¯å“åº”", {"error_message": message})
        return {
            "success": False,
            "tool": self.tool_name,
            "error": message
        }


def create_mcp_tool() -> DocSyncTool:
    """åˆ›å»ºMCPå·¥å…·å®ä¾‹"""
    return DocSyncTool()


# å‘½ä»¤è¡Œæ¥å£ï¼Œç”¨äºæµ‹è¯•
def main():
    """å‘½ä»¤è¡Œæµ‹è¯•æ¥å£"""
    import argparse

    parser = argparse.ArgumentParser(description="MCP doc_sync unified tool")
    parser.add_argument("project_path", nargs="?", help="Project path (optional)")
    parser.add_argument("--mode", choices=["auto", "init", "update", "status"], 
                       default="auto", help="Operation mode")
    parser.add_argument("--no-record", action="store_true", help="Disable change recording")

    args = parser.parse_args()

    # æ„å»ºå‚æ•°
    arguments = {
        "project_path": args.project_path,
        "mode": args.mode,
        "record_changes": not args.no_record
    }

    # æ‰§è¡Œå·¥å…·
    tool = create_mcp_tool()
    result = tool.execute(arguments)

    # è¾“å‡ºç»“æœ
    print(json.dumps(result, indent=2, ensure_ascii=False))


if __name__ == "__main__":
    main()