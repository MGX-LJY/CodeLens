"""
MCP doc_guide å·¥å…·å®ç°
æ™ºèƒ½åˆ†æé¡¹ç›®ç‰¹å¾ï¼Œä¸ºAIæä¾›æ–‡æ¡£ç”Ÿæˆç­–ç•¥
"""
import argparse
import json
import os
import sys
import time
from collections import Counter
from pathlib import Path
from typing import Dict, Any, List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°pathä»¥å¯¼å…¥å…¶ä»–æ¨¡å—
project_root = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
sys.path.insert(0, project_root)

# å¿…é¡»åœ¨sys.pathä¿®æ”¹åå†å¯¼å…¥
from src.services.file_service import FileService  # noqa: E402
from src.logging import get_logger  # noqa: E402


class ProjectAnalyzer:
    """é¡¹ç›®åˆ†æå™¨"""

    def __init__(self):
        self.file_service = FileService()
        self.logger = get_logger(component="ProjectAnalyzer", operation="init")
        self.logger.info("ProjectAnalyzer åˆå§‹åŒ–å®Œæˆ")

        # é¡¹ç›®ç±»å‹ç‰¹å¾æ¨¡å¼
        self.project_patterns = {
            "python": {
                "files": ["requirements.txt", "setup.py", "pyproject.toml", "main.py", "app.py"],
                "directories": ["src", "lib", "tests"],
                "extensions": [".py"],
                "imports": ["import", "from", "django", "flask", "fastapi", "requests"]
            },
            "javascript": {
                "files": ["package.json", "package-lock.json", "yarn.lock", "index.js", "app.js"],
                "directories": ["node_modules", "src", "lib", "dist"],
                "extensions": [".js", ".jsx", ".ts", ".tsx"],
                "imports": ["require", "import", "export", "react", "vue", "angular"]
            },
            "java": {
                "files": ["pom.xml", "build.gradle", "gradle.properties"],
                "directories": ["src/main", "src/test", "target", "build"],
                "extensions": [".java", ".kt"],
                "imports": ["package", "import", "spring", "maven", "gradle"]
            },
            "go": {
                "files": ["go.mod", "go.sum", "main.go"],
                "directories": ["cmd", "internal", "pkg"],
                "extensions": [".go"],
                "imports": ["package", "import", "func", "gin", "echo"]
            },
            "rust": {
                "files": ["Cargo.toml", "Cargo.lock"],
                "directories": ["src", "target"],
                "extensions": [".rs"],
                "imports": ["use", "mod", "extern", "actix", "tokio"]
            }
        }

        # æ¡†æ¶æ£€æµ‹æ¨¡å¼
        self.framework_patterns = {
            "django": ["django", "settings.py", "urls.py", "models.py", "views.py"],
            "flask": ["flask", "app.py", "@app.route", "Flask(__name__)"],
            "fastapi": ["fastapi", "FastAPI", "@app.get", "@app.post", "uvicorn"],
            "react": ["react", "jsx", "package.json", "src/App.js", "public/index.html"],
            "vue": ["vue", "package.json", "src/main.js", "public/index.html"],
            "spring": ["spring", "pom.xml", "@SpringBootApplication", "@RestController"],
            "gin": ["gin", "go.mod", "gin.Engine", "gin.Default"],
            "express": ["express", "package.json", "app.use", "app.listen"]
        }

    def analyze_project(self, project_path: str, config: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æé¡¹ç›®ç‰¹å¾"""
        operation_id = self.logger.log_operation_start("analyze_project", project_path=str(project_path))
        start_time = time.time()
        
        project_path = Path(project_path)
        self.logger.info("å¼€å§‹åˆ†æé¡¹ç›®", {
            "project_path": str(project_path),
            "config": config,
            "operation_id": operation_id
        })

        # è·å–é¡¹ç›®æ–‡ä»¶ä¿¡æ¯
        self.logger.debug("å¼€å§‹è·å–é¡¹ç›®æ–‡ä»¶ä¿¡æ¯")
        file_info = self._get_file_info(project_path, config)
        self.logger.debug("æ–‡ä»¶ä¿¡æ¯è·å–å®Œæˆ", {"file_count": len(file_info["files"])})

        # æ£€æµ‹é¡¹ç›®ç±»å‹
        self.logger.debug("å¼€å§‹æ£€æµ‹é¡¹ç›®ç±»å‹")
        project_type = self._detect_project_type(project_path, file_info)
        self.logger.info("é¡¹ç›®ç±»å‹æ£€æµ‹å®Œæˆ", {"project_type": project_type})

        # æ£€æµ‹ä¸»è¦æ¡†æ¶
        self.logger.debug("å¼€å§‹æ£€æµ‹ä¸»è¦æ¡†æ¶")
        main_framework = self._detect_framework(project_path, file_info, project_type)
        self.logger.info("ä¸»è¦æ¡†æ¶æ£€æµ‹å®Œæˆ", {"main_framework": main_framework})

        # è¯†åˆ«åŠŸèƒ½æ¨¡å—
        self.logger.debug("å¼€å§‹è¯†åˆ«åŠŸèƒ½æ¨¡å—")
        identified_modules = self._identify_modules(project_path, file_info, project_type)
        self.logger.info("åŠŸèƒ½æ¨¡å—è¯†åˆ«å®Œæˆ", {"modules_count": len(identified_modules), "modules": identified_modules})

        # è¯„ä¼°ä»£ç å¤æ‚åº¦
        self.logger.debug("å¼€å§‹è¯„ä¼°ä»£ç å¤æ‚åº¦")
        complexity = self._assess_complexity(file_info)
        self.logger.info("ä»£ç å¤æ‚åº¦è¯„ä¼°å®Œæˆ", {"complexity": complexity})

        # è¯†åˆ«å…³é”®æ–‡ä»¶
        self.logger.debug("å¼€å§‹è¯†åˆ«å…³é”®æ–‡ä»¶")
        key_files = self._identify_key_files(project_path, file_info, project_type)
        self.logger.info("å…³é”®æ–‡ä»¶è¯†åˆ«å®Œæˆ", {"key_files_count": len(key_files)})

        analysis_result = {
            "project_type": project_type,
            "main_framework": main_framework,
            "identified_modules": identified_modules,
            "code_complexity": complexity,
            "file_count": len(file_info["files"]),
            "key_files": key_files,
            "file_distribution": file_info["file_distribution"],
            "directory_structure": file_info["directory_structure"]
        }
        
        duration_ms = (time.time() - start_time) * 1000
        self.logger.log_operation_end("analyze_project", operation_id, duration_ms, True, **analysis_result)
        
        return analysis_result

    def generate_documentation_strategy(self, analysis: Dict[str, Any], focus_areas: List[str]) -> Dict[str, Any]:
        """ç”Ÿæˆæ–‡æ¡£ç­–ç•¥"""
        operation_id = self.logger.log_operation_start("generate_documentation_strategy", 
                                                       project_type=analysis.get("project_type"),
                                                       complexity=analysis.get("code_complexity"),
                                                       file_count=analysis.get("file_count"))
        
        project_type = analysis["project_type"]
        complexity = analysis["code_complexity"]
        file_count = analysis["file_count"]
        
        self.logger.info("å¼€å§‹ç”Ÿæˆæ–‡æ¡£ç­–ç•¥", {
            "project_type": project_type,
            "complexity": complexity,
            "file_count": file_count,
            "focus_areas": focus_areas
        })

        # ç¡®å®šæ‰§è¡Œé˜¶æ®µé¡ºåº
        if complexity == "simple" and file_count < 20:
            execution_phases = ["files_first", "architecture_second", "project_last"]
            priority_strategy = "sequential"
        elif complexity == "complex" or file_count > 100:
            execution_phases = ["architecture_first", "files_second", "project_last"]
            priority_strategy = "top_down"
        else:
            execution_phases = ["files_first", "architecture_second", "project_last"]
            priority_strategy = "bottom_up"

        # ç¡®å®šä¼˜å…ˆæ–‡ä»¶
        priority_files = analysis["key_files"][:10]  # æœ€å¤š10ä¸ªä¼˜å…ˆæ–‡ä»¶

        # ä¼°è®¡æ¨¡æ¿æ•°é‡
        estimated_files = min(file_count, 30)  # æ–‡ä»¶å±‚æœ€å¤š30ä¸ª
        estimated_templates = estimated_files + 6 + 4  # æ–‡ä»¶+æ¶æ„+é¡¹ç›®

        strategy_result = {
            "execution_phases": execution_phases,
            "priority_strategy": priority_strategy,
            "priority_files": priority_files,
            "estimated_templates": estimated_templates,
            "complexity_level": complexity
        }
        
        self.logger.log_operation_end("generate_documentation_strategy", operation_id, success=True, **strategy_result)
        
        return strategy_result

    def generate_generation_plan(self, analysis: Dict[str, Any], strategy: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆå…·ä½“çš„ç”Ÿæˆè®¡åˆ’"""
        # Phase 1: æ‰«æä»»åŠ¡
        phase_1_scan = ["project_scan_and_analysis"]

        # Phase 2: æ–‡ä»¶å±‚ä»»åŠ¡
        priority_files = strategy["priority_files"]
        other_files = [f for f in analysis["key_files"] if f not in priority_files]
        phase_2_files = priority_files + other_files[:20]  # æœ€å¤šå¤„ç†20ä¸ªæ–‡ä»¶

        # Phase 3: æ¨¡å—å±‚ä»»åŠ¡
        identified_modules = analysis["identified_modules"]
        phase_3_modules = [
            f"module_{module.lower().replace(' ', '_')}"
            for module in identified_modules
        ]

        # Phase 4: æ¶æ„å±‚ä»»åŠ¡
        project_type = analysis["project_type"]
        phase_4_architecture = self._get_architecture_components(project_type)

        # Phase 5: é¡¹ç›®å±‚ä»»åŠ¡
        phase_5_project = ["project_readme"]

        return {
            "phase_1_scan": phase_1_scan,
            "phase_2_files": phase_2_files,
            "phase_3_modules": phase_3_modules,
            "phase_4_architecture": phase_4_architecture,
            "phase_5_project": phase_5_project,
            "estimated_duration": self._estimate_duration(
                len(phase_2_files), len(phase_3_modules), len(phase_4_architecture)
            )
        }

    def _get_file_info(self, project_path: Path, config: Dict[str, Any]) -> Dict[str, Any]:
        """è·å–æ–‡ä»¶ä¿¡æ¯"""
        ignore_patterns = config.get("ignore_patterns", {})
        file_patterns = ignore_patterns.get("files", [])
        dir_patterns = ignore_patterns.get("directories", [])

        # æ‰©å±•é»˜è®¤å¿½ç•¥æ¨¡å¼
        default_ignore_files = ["*.md", "*.txt", "*.log", "*.tmp", "*.pyc", "*.class"]
        default_ignore_dirs = ["__pycache__", ".git", "node_modules", ".idea", "venv", "env", "dist", "build"]

        all_ignore_files = list(set(file_patterns + default_ignore_files))
        all_ignore_dirs = list(set(dir_patterns + default_ignore_dirs))

        # æ‰«ææ–‡ä»¶
        files = []
        file_distribution = Counter()
        directory_structure = []

        for file_path in project_path.rglob("*"):
            if file_path.is_file():
                # æ£€æŸ¥æ˜¯å¦åº”è¯¥å¿½ç•¥
                if self._should_ignore_file(file_path, all_ignore_files, all_ignore_dirs):
                    continue

                relative_path = file_path.relative_to(project_path)
                files.append(str(relative_path))
                file_distribution[file_path.suffix] += 1

                # è®°å½•ç›®å½•ç»“æ„
                parent_dir = str(relative_path.parent)
                if parent_dir != "." and parent_dir not in directory_structure:
                    directory_structure.append(parent_dir)

        return {
            "files": files,
            "file_distribution": dict(file_distribution),
            "directory_structure": directory_structure
        }

    @staticmethod
    def _should_ignore_file(file_path: Path, ignore_files: List[str], ignore_dirs: List[str]) -> bool:
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åº”è¯¥è¢«å¿½ç•¥"""
        # æ£€æŸ¥æ–‡ä»¶åæ¨¡å¼
        for pattern in ignore_files:
            if file_path.match(pattern):
                return True

        # æ£€æŸ¥ç›®å½•æ¨¡å¼
        for part in file_path.parts:
            for pattern in ignore_dirs:
                if part == pattern or part.startswith(pattern):
                    return True

        return False

    def _detect_project_type(self, _project_path: Path, file_info: Dict[str, Any]) -> str:
        """æ£€æµ‹é¡¹ç›®ç±»å‹"""
        scores = {}

        for proj_type, patterns in self.project_patterns.items():
            score = 0

            # æ£€æŸ¥ç‰¹å¾æ–‡ä»¶
            for file_name in patterns["files"]:
                if any(file_name in f for f in file_info["files"]):
                    score += 3

            # æ£€æŸ¥ç›®å½•ç»“æ„
            for dir_name in patterns["directories"]:
                if any(dir_name in d for d in file_info["directory_structure"]):
                    score += 2

            # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
            for ext in patterns["extensions"]:
                if ext in file_info["file_distribution"]:
                    score += file_info["file_distribution"][ext]

            scores[proj_type] = score

        if not scores:
            return "unknown"

        return max(scores, key=scores.get)

    def _detect_framework(self, project_path: Path, file_info: Dict[str, Any], _project_type: str) -> str:
        """æ£€æµ‹ä¸»è¦æ¡†æ¶"""
        scores = {}

        # è¯»å–å‡ ä¸ªå…³é”®æ–‡ä»¶çš„å†…å®¹æ¥æ£€æµ‹æ¡†æ¶
        key_files = ["requirements.txt", "package.json", "go.mod", "Cargo.toml", "pom.xml"]
        file_contents = []

        for file_name in key_files:
            file_path = project_path / file_name
            if file_path.exists():
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read().lower()
                        file_contents.append(content)
                except (IOError, OSError, UnicodeDecodeError):
                    continue

        # ä¹Ÿæ£€æŸ¥ä¸€äº›æºä»£ç æ–‡ä»¶
        source_files = [f for f in file_info["files"] if
                        any(f.endswith(ext) for ext in [".py", ".js", ".go", ".rs", ".java"])][:5]
        for file_name in source_files:
            file_path = project_path / file_name
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read().lower()[:2000]  # åªè¯»å‰2000å­—ç¬¦
                    file_contents.append(content)
            except (IOError, OSError, UnicodeDecodeError):
                continue

        all_content = " ".join(file_contents)

        # æ£€æµ‹æ¡†æ¶
        for framework, patterns in self.framework_patterns.items():
            score = 0
            for pattern in patterns:
                score += all_content.count(pattern.lower())
            scores[framework] = score

        if not scores:
            return "custom"

        best_framework = max(scores, key=scores.get)
        return best_framework if scores[best_framework] > 0 else "custom"

    @staticmethod
    def _identify_modules(project_path: Path, file_info: Dict[str, Any], project_type: str) -> List[str]:
        """ğŸ§  AIé©±åŠ¨çš„æ™ºèƒ½æ¨¡å—è¯†åˆ« - åŸºäºè¯­ä¹‰ç†è§£å’Œä¸šåŠ¡é€»è¾‘"""
        
        # ğŸ“¦ ç¬¬ä¸€æ­¥ï¼šè¯†åˆ«å®é™…PythonåŒ…ï¼ˆåŒ…å«__init__.pyçš„ç›®å½•ï¼‰
        real_packages = []
        for directory in file_info["directory_structure"]:
            dir_path = project_path / directory
            if (dir_path / "__init__.py").exists():
                # æå–åŒ…åï¼ˆå»é™¤è·¯å¾„å‰ç¼€ï¼‰
                package_name = directory.split("/")[-1]
                if package_name not in ["__pycache__", ".pytest_cache"]:
                    real_packages.append(package_name)
        
        # ç›´æ¥è¿”å›å®é™…åŒ…ç»“æ„
        return [pkg for pkg in real_packages if pkg != "root"]

    @staticmethod
    def _assess_complexity(file_info: Dict[str, Any]) -> str:
        """è¯„ä¼°ä»£ç å¤æ‚åº¦"""
        file_count = len(file_info["files"])
        dir_count = len(file_info["directory_structure"])

        if file_count < 10 and dir_count < 5:
            return "simple"
        elif file_count < 50 and dir_count < 15:
            return "medium"
        else:
            return "complex"

    @staticmethod
    def _identify_key_files(_project_path: Path, file_info: Dict[str, Any], project_type: str) -> List[str]:
        """è¯†åˆ«å…³é”®æ–‡ä»¶"""
        key_files = []

        # ç³»ç»Ÿæ–‡ä»¶æ’é™¤åˆ—è¡¨
        system_files = {'.DS_Store', 'Thumbs.db', '.gitignore', '.gitkeep'}
        system_patterns = {'*.log', '*.tmp', '*.temp'}

        # é¡¹ç›®ç±»å‹ç‰¹å®šçš„å…³é”®æ–‡ä»¶
        type_specific = {
            "python": ["main.py", "app.py", "__init__.py", "models.py", "views.py", "settings.py"],
            "javascript": ["index.js", "app.js", "server.js", "main.js", "package.json"],
            "java": ["Main.java", "Application.java", "Controller.java", "Service.java"],
            "go": ["main.go", "server.go", "handler.go", "service.go"],
            "rust": ["main.rs", "lib.rs", "mod.rs"]
        }

        important_patterns = type_specific.get(project_type, [])

        # æŒ‰é‡è¦æ€§æ’åºæ–‡ä»¶
        scored_files = []

        for file_name in file_info["files"]:
            file_lower = file_name.lower()
            file_basename = file_name.split('/')[-1]  # è·å–æ–‡ä»¶åéƒ¨åˆ†
            
            # æ’é™¤ç³»ç»Ÿæ–‡ä»¶
            if file_basename in system_files:
                continue
                
            # æ’é™¤åŒ¹é…ç³»ç»Ÿæ¨¡å¼çš„æ–‡ä»¶
            if any(file_basename.endswith(pattern.replace('*', '')) for pattern in system_patterns):
                continue
            
            score = 0

            # ä¸»æ–‡ä»¶å¾—åˆ†æœ€é«˜
            if any(pattern.lower() in file_lower for pattern in important_patterns):
                score += 10

            # æ ¹æ®æ–‡ä»¶åç‰¹å¾è¯„åˆ†
            if "main" in file_lower or "app" in file_lower:
                score += 8
            if "config" in file_lower or "setting" in file_lower:
                score += 6
            if "model" in file_lower or "schema" in file_lower:
                score += 5
            if "controller" in file_lower or "handler" in file_lower:
                score += 5
            if "service" in file_lower or "business" in file_lower:
                score += 4
            if "util" in file_lower or "helper" in file_lower:
                score += 3

            # æ ¹æ®æ–‡ä»¶ä½ç½®è¯„åˆ†ï¼ˆæ ¹ç›®å½•æˆ–srcç›®å½•ä¼˜å…ˆï¼‰
            if "/" not in file_name or file_name.startswith("src/"):
                score += 2

            scored_files.append((file_name, score))

        # æŒ‰åˆ†æ•°æ’åºï¼Œè¿”å›å‰20ä¸ª
        scored_files.sort(key=lambda x: x[1], reverse=True)
        return [file_name for file_name, score in scored_files[:20] if score > 0]


    @staticmethod
    def _get_architecture_components(project_type: str) -> List[str]:
        """è·å–æ¶æ„ç»„ä»¶"""
        base_components = ["system_overview", "tech_stack", "data_flow"]

        type_specific = {
            "python": ["deployment_architecture", "package_structure", "dependency_management"],
            "javascript": ["build_process", "module_system", "runtime_environment"],
            "java": ["class_hierarchy", "spring_configuration", "build_lifecycle"],
            "go": ["package_organization", "concurrency_model", "build_deployment"],
            "rust": ["module_system", "memory_management", "cargo_ecosystem"]
        }

        specific_components = type_specific.get(project_type, ["general_architecture"])
        return base_components + specific_components[:3]  # æœ€å¤š6ä¸ªç»„ä»¶

    @staticmethod
    def _estimate_duration(file_count: int, module_count: int, arch_count: int) -> str:
        """ä¼°è®¡å®Œæˆæ—¶é—´"""
        # å‡è®¾æ¯ä¸ªæ–‡ä»¶3åˆ†é’Ÿï¼Œæ¯ä¸ªæ¨¡å—5åˆ†é’Ÿï¼Œæ¯ä¸ªæ¶æ„ç»„ä»¶10åˆ†é’Ÿ
        total_minutes = file_count * 3 + module_count * 5 + arch_count * 10 + 30  # åŠ 30åˆ†é’ŸåŸºç¡€æ—¶é—´

        hours = total_minutes // 60
        minutes = total_minutes % 60

        if hours > 0:
            return f"{hours} hours {minutes} minutes"
        else:
            return f"{minutes} minutes"


class DocGuideTool:
    """MCP doc_guide å·¥å…·ç±»"""

    def __init__(self):
        self.tool_name = "doc_guide"
        self.description = "æ™ºèƒ½åˆ†æé¡¹ç›®ç‰¹å¾ï¼Œä¸ºAIæä¾›æ–‡æ¡£ç”Ÿæˆç­–ç•¥"
        self.analyzer = ProjectAnalyzer()
        self.logger = get_logger(component="DocGuideTool", operation="init")
        self.logger.info("DocGuideTool åˆå§‹åŒ–å®Œæˆ")

    def get_tool_definition(self) -> Dict[str, Any]:
        """è·å–MCPå·¥å…·å®šä¹‰"""
        return {
            "name": self.tool_name,
            "description": self.description,
            "inputSchema": {
                "type": "object",
                "properties": {
                    "project_path": {
                        "type": "string",
                        "description": "è¦åˆ†æçš„é¡¹ç›®è·¯å¾„"
                    },
                    "project_type": {
                        "type": "string",
                        "enum": ["auto", "python", "javascript", "java", "go", "rust"],
                        "description": "é¡¹ç›®ç±»å‹ï¼Œautoä¸ºè‡ªåŠ¨æ£€æµ‹"
                    },
                    "analysis_depth": {
                        "type": "string",
                        "enum": ["basic", "detailed", "comprehensive"],
                        "description": "åˆ†ææ·±åº¦"
                    },
                    "ignore_patterns": {
                        "type": "object",
                        "properties": {
                            "files": {
                                "type": "array",
                                "items": {"type": "string"},
                                "description": "å¿½ç•¥çš„æ–‡ä»¶æ¨¡å¼"
                            },
                            "directories": {
                                "type": "array",
                                "items": {"type": "string"},
                                "description": "å¿½ç•¥çš„ç›®å½•æ¨¡å¼"
                            }
                        }
                    },
                    "focus_areas": {
                        "type": "array",
                        "items": {
                            "type": "string",
                            "enum": ["architecture", "modules", "files", "project"]
                        },
                        "description": "é‡ç‚¹å…³æ³¨çš„é¢†åŸŸ"
                    }
                },
                "required": []
            }
        }

    def execute(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œdoc_guideå·¥å…·"""
        operation_id = self.logger.log_operation_start("execute_doc_guide", 
                                                       project_path=arguments.get("project_path"),
                                                       create_analysis_file=arguments.get("create_analysis_file", True))
        start_time = time.time()
        
        try:
            self.logger.info("å¼€å§‹æ‰§è¡Œdoc_guideå·¥å…·", {"arguments": arguments, "operation_id": operation_id})
            
            # å‚æ•°éªŒè¯ - å¦‚æœæ²¡æœ‰æä¾›project_pathï¼Œä½¿ç”¨å½“å‰å·¥ä½œç›®å½•
            project_path = arguments.get("project_path")
            if not project_path:
                project_path = os.getcwd()
                self.logger.info("æœªæä¾›project_pathï¼Œä½¿ç”¨å½“å‰å·¥ä½œç›®å½•", {
                    "current_working_directory": project_path
                })
            
            self.logger.debug("éªŒè¯project_pathå‚æ•°", {"project_path": project_path})
                
            if not os.path.exists(project_path):
                error_msg = f"é¡¹ç›®è·¯å¾„ä¸å­˜åœ¨: {project_path}"
                self.logger.error(error_msg)
                return self._error_response("Invalid project path")

            # è·å–å‚æ•°
            project_type = arguments.get("project_type", "auto")
            analysis_depth = arguments.get("analysis_depth", "detailed")
            ignore_patterns = arguments.get("ignore_patterns", {})
            focus_areas = arguments.get("focus_areas", ["architecture", "modules", "files", "project"])

            config = {
                "project_type": project_type,
                "analysis_depth": analysis_depth,
                "ignore_patterns": ignore_patterns,
                "focus_areas": focus_areas
            }

            # åˆ†æé¡¹ç›®
            self.logger.info("å¼€å§‹åˆ†æé¡¹ç›®", {"project_path": project_path, "config": config})
            analysis = self.analyzer.analyze_project(project_path, config)
            self.logger.info("é¡¹ç›®åˆ†æå®Œæˆ", {"analysis_summary": {
                "project_type": analysis.get("project_type"),
                "file_count": analysis.get("file_count"),
                "complexity": analysis.get("code_complexity")
            }})

            # ç”Ÿæˆæ–‡æ¡£ç­–ç•¥
            self.logger.info("å¼€å§‹ç”Ÿæˆæ–‡æ¡£ç­–ç•¥", {"focus_areas": focus_areas})
            strategy = self.analyzer.generate_documentation_strategy(analysis, focus_areas)
            self.logger.info("æ–‡æ¡£ç­–ç•¥ç”Ÿæˆå®Œæˆ", {"strategy_summary": {
                "priority_strategy": strategy.get("priority_strategy"),
                "estimated_templates": strategy.get("estimated_templates")
            }})

            # ç”Ÿæˆå…·ä½“è®¡åˆ’
            self.logger.info("å¼€å§‹ç”Ÿæˆå…·ä½“è®¡åˆ’")
            plan = self.analyzer.generate_generation_plan(analysis, strategy)
            self.logger.info("å…·ä½“è®¡åˆ’ç”Ÿæˆå®Œæˆ")

            # ä¿å­˜analysis.jsonåˆ°é¡¹ç›®.codelensç›®å½•
            self.logger.info("å¼€å§‹ä¿å­˜åˆ†æç»“æœåˆ°.codelensç›®å½•")
            analysis_data = {
                "project_analysis": analysis,
                "documentation_strategy": strategy,
                "generation_plan": plan,
                "timestamp": time.time(),
                "version": "1.0"
            }
            
            codelens_dir = Path(project_path) / ".codelens"
            self.logger.debug("åˆ›å»º.codelensç›®å½•", {"dir_path": str(codelens_dir)})
            codelens_dir.mkdir(exist_ok=True)
            
            analysis_file = codelens_dir / "analysis.json"
            self.logger.debug("å†™å…¥åˆ†ææ–‡ä»¶", {"file_path": str(analysis_file)})
            
            with open(analysis_file, 'w', encoding='utf-8') as f:
                json.dump(analysis_data, f, indent=2, ensure_ascii=False)
            
            duration_ms = (time.time() - start_time) * 1000
            self.logger.log_operation_end("execute_doc_guide", operation_id, duration_ms, True,
                                        project_type=analysis['project_type'],
                                        complexity=analysis['code_complexity'],
                                        file_count=analysis['file_count'],
                                        analysis_file=str(analysis_file))

            return self._success_response({
                "project_analysis": analysis,
                "documentation_strategy": strategy,
                "generation_plan": plan,
                "analysis_file": str(analysis_file)
            })

        except (OSError, IOError, ValueError) as e:
            duration_ms = (time.time() - start_time) * 1000
            self.logger.log_operation_end("execute_doc_guide", operation_id, duration_ms, False, error=str(e))
            self.logger.error(f"é¡¹ç›®åˆ†æå¤±è´¥: {str(e)}", exc_info=e)
            return self._error_response(f"Analysis failed: {str(e)}")
        except Exception as e:
            duration_ms = (time.time() - start_time) * 1000
            self.logger.log_operation_end("execute_doc_guide", operation_id, duration_ms, False, error=str(e))
            self.logger.error(f"doc_guideå·¥å…·æ‰§è¡Œå¤±è´¥: {str(e)}", exc_info=e)
            return self._error_response(f"Tool execution failed: {str(e)}")

    def _success_response(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """æˆåŠŸå“åº”"""
        self.logger.debug("ç”ŸæˆæˆåŠŸå“åº”", {"data_keys": list(data.keys()) if data else []})
        return {
            "success": True,
            "tool": self.tool_name,
            "data": data
        }

    def _error_response(self, message: str) -> Dict[str, Any]:
        """é”™è¯¯å“åº”"""
        self.logger.error("ç”Ÿæˆé”™è¯¯å“åº”", {"error_message": message})
        return {
            "success": False,
            "tool": self.tool_name,
            "error": message
        }


def create_mcp_tool() -> DocGuideTool:
    """åˆ›å»ºMCPå·¥å…·å®ä¾‹"""
    return DocGuideTool()


# å‘½ä»¤è¡Œæ¥å£ï¼Œç”¨äºæµ‹è¯•
def main():
    """å‘½ä»¤è¡Œæµ‹è¯•æ¥å£"""

    parser = argparse.ArgumentParser(description="MCP doc_guide tool")
    parser.add_argument("project_path", help="Project path to analyze")
    parser.add_argument("--type", dest="project_type",
                        choices=["auto", "python", "javascript", "java", "go", "rust"],
                        default="auto", help="Project type")
    parser.add_argument("--depth", dest="analysis_depth",
                        choices=["basic", "detailed", "comprehensive"],
                        default="detailed", help="Analysis depth")
    parser.add_argument("--focus", nargs="+",
                        choices=["architecture", "modules", "files", "project"],
                        default=["architecture", "modules", "files", "project"],
                        help="Focus areas")

    args = parser.parse_args()

    # æ„å»ºå‚æ•°
    arguments = {
        "project_path": args.project_path,
        "project_type": args.project_type,
        "analysis_depth": args.analysis_depth,
        "focus_areas": args.focus
    }

    # æ‰§è¡Œå·¥å…·
    tool = create_mcp_tool()
    result = tool.execute(arguments)

    # è¾“å‡ºç»“æœ
    print(json.dumps(result, indent=2, ensure_ascii=False))


if __name__ == "__main__":
    main()
