"""
MCP task_init å·¥å…·å®ç°
åŸºäºé¡¹ç›®åˆ†æç»“æœï¼Œç”Ÿæˆå®Œæ•´çš„é˜¶æ®µæ€§ä»»åŠ¡åˆ—è¡¨
"""
import sys
import os
import json
import time
from pathlib import Path
from typing import Dict, Any, List, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°pathä»¥å¯¼å…¥å…¶ä»–æ¨¡å—
project_root = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
sys.path.insert(0, project_root)

from src.task_engine.task_manager import TaskManager, TaskType, TaskStatus
from src.task_engine.phase_controller import PhaseController, Phase

# å¯¼å…¥æ—¥å¿—ç³»ç»Ÿ
import logging


class TaskPlanGenerator:
    """ä»»åŠ¡è®¡åˆ’ç”Ÿæˆå™¨"""

    def __init__(self):
        # æ¨¡æ¿æ˜ å°„å…³ç³»
        self.template_mapping = {
            TaskType.SCAN: "project_scan_summary",  # æ·»åŠ scanä»»åŠ¡æ¨¡æ¿æ˜ å°„
            TaskType.FILE_SUMMARY: "file_summary",
            TaskType.MODULE_ANALYSIS: "module_analysis",
            TaskType.MODULE_RELATIONS: "module_relations",
            TaskType.DEPENDENCY_GRAPH: "dependency_graph",
            TaskType.MODULE_README: "module_readme",
            TaskType.MODULE_API: "module_api",
            TaskType.MODULE_FLOW: "module_flow",
            TaskType.ARCHITECTURE: "architecture",
            TaskType.TECH_STACK: "tech_stack",
            TaskType.DATA_FLOW: "data_flow",
            TaskType.SYSTEM_ARCHITECTURE: "system_architecture",
            TaskType.COMPONENT_DIAGRAM: "component_diagram",
            TaskType.DEPLOYMENT_DIAGRAM: "deployment_diagram",
            TaskType.PROJECT_README: "project_readme"
        }

        # ä¼˜å…ˆçº§æ˜ å°„
        self.priority_mapping = {
            "high": ["main.py", "app.py", "index.js", "server.js", "main.go", "main.rs"],
            "normal": ["config", "model", "service", "controller", "handler"],
            "low": ["util", "helper", "test", "spec"]
        }

    def generate_tasks(self, project_path: str, analysis_result: Dict[str, Any],
                       task_granularity: str = "file", parallel_tasks: bool = False,
                       custom_priorities: Dict[str, Any] = None) -> Dict[str, Any]:
        """ç”Ÿæˆå®Œæ•´çš„ä»»åŠ¡è®¡åˆ’"""

        # æå–åˆ†æç»“æœ - ä¿®å¤åµŒå¥—JSONç»“æ„è§£æ
        if "data" in analysis_result:
            # å¦‚æœæ˜¯MCPå·¥å…·çš„è¾“å‡ºæ ¼å¼
            data = analysis_result["data"]
            project_analysis = data.get("project_analysis", {})
            plan = data.get("generation_plan", {})
        else:
            # å¦‚æœæ˜¯ç›´æ¥çš„åˆ†æç»“æœæ ¼å¼
            project_analysis = analysis_result.get("project_analysis", {})
            plan = analysis_result.get("generation_plan", {})

        # ç”Ÿæˆå…¨å±€scanä»»åŠ¡IDï¼Œç¡®ä¿ä¾èµ–å…³ç³»ä¸€è‡´
        scan_task_id = f"scan_{int(time.time() * 1000000)}"  # ä½¿ç”¨æ›´é«˜ç²¾åº¦é¿å…å†²çª
        
        # ç”Ÿæˆå„é˜¶æ®µä»»åŠ¡
        phase_1_tasks = self._generate_phase_1_tasks(project_path, project_analysis, scan_task_id)
        phase_2_tasks = self._generate_phase_2_tasks(project_path, plan, scan_task_id, custom_priorities)
        phase_3_tasks = self._generate_phase_3_tasks(project_path, project_analysis, phase_2_tasks)
        phase_4_tasks = self._generate_phase_4_tasks(project_path, project_analysis, phase_3_tasks)
        phase_5_tasks = self._generate_phase_5_tasks(project_path, project_analysis, phase_4_tasks)

        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        all_tasks = phase_1_tasks + phase_2_tasks + phase_3_tasks + phase_4_tasks + phase_5_tasks

        task_plan = {
            "total_phases": 5,
            "total_tasks": len(all_tasks),
            "estimated_duration": plan.get("estimated_duration", "Unknown"),
            "dependencies_graph": self._build_dependency_graph(all_tasks),
            "task_distribution": {
                "phase_1_scan": len(phase_1_tasks),
                "phase_2_files": len(phase_2_tasks),
                "phase_3_modules": len(phase_3_tasks),
                "phase_4_architecture": len(phase_4_tasks),
                "phase_5_project": len(phase_5_tasks)
            }
        }

        # æ„å»ºå®Œæ•´å“åº”
        return {
            "task_plan": task_plan,
            "phase_1_scan": {
                "description": "é¡¹ç›®æ‰«æå’Œåˆ†æ",
                "dependencies": [],
                "estimated_time": "5 minutes",
                "tasks": phase_1_tasks
            },
            "phase_2_files": {
                "description": f"æ–‡ä»¶å±‚æ–‡æ¡£ç”Ÿæˆï¼ˆ{len(phase_2_tasks)}ä¸ªæ–‡ä»¶ï¼‰",
                "dependencies": ["phase_1_complete"],
                "estimated_time": f"{len(phase_2_tasks) * 3} minutes",
                "tasks": phase_2_tasks
            },
            "phase_3_modules": {
                "description": f"æ¨¡å—å±‚æ–‡æ¡£ç”Ÿæˆï¼ˆ{len(phase_3_tasks)}ä¸ªæ¨¡æ¿ï¼‰",
                "dependencies": ["phase_2_complete"],
                "estimated_time": f"{len(phase_3_tasks) * 5} minutes",
                "tasks": phase_3_tasks
            },
            "phase_4_architecture": {
                "description": f"æ¶æ„å±‚æ–‡æ¡£ç”Ÿæˆï¼ˆ{len(phase_4_tasks)}ä¸ªæ¨¡æ¿ï¼‰",
                "dependencies": ["phase_3_complete"],
                "estimated_time": f"{len(phase_4_tasks) * 10} minutes",
                "tasks": phase_4_tasks
            },
            "phase_5_project": {
                "description": "é¡¹ç›®å±‚æ–‡æ¡£ç”Ÿæˆï¼ˆä»…README.mdï¼‰",
                "dependencies": ["phase_4_complete"],
                "estimated_time": "10 minutes",
                "tasks": phase_5_tasks
            }
        }

    def _generate_phase_1_tasks(self, project_path: str, analysis: Dict[str, Any], scan_task_id: str) -> List[Dict[str, Any]]:
        """ç”Ÿæˆç¬¬ä¸€é˜¶æ®µä»»åŠ¡ï¼ˆé¡¹ç›®æ‰«æï¼‰"""

        return [{
            "id": scan_task_id,
            "type": "scan",
            "description": "æ‰«æé¡¹ç›®æ–‡ä»¶ç»“æ„å’ŒåŸºæœ¬ä¿¡æ¯",
            "phase": "phase_1_scan",
            "template": "project_scan_summary",  # ä½¿ç”¨æ¨¡æ¿è€Œä¸æ˜¯None
            "output_path": "docs/analysis/project-scan.md",  # æ·»åŠ è¾“å‡ºè·¯å¾„
            "dependencies": [],
            "priority": "high",
            "estimated_time": "5 minutes",
            "status": "pending",
            "metadata": {
                "project_type": analysis.get("project_type", "unknown"),
                "file_count": analysis.get("file_count", 0),
                "complexity": analysis.get("code_complexity", "unknown")
            }
        }]

    def _generate_phase_2_tasks(self, project_path: str, plan: Dict[str, Any], scan_task_id: str,
                                custom_priorities: Dict[str, Any] = None) -> List[Dict[str, Any]]:
        """ç”Ÿæˆç¬¬äºŒé˜¶æ®µä»»åŠ¡ï¼ˆæ–‡ä»¶å±‚ï¼‰"""
        tasks = []
        files_to_process = plan.get("phase_2_files", [])

        for i, file_path in enumerate(files_to_process):
            task_id = f"file_summary_{int(time.time() * 1000)}_{i}"

            # ç¡®å®šä¼˜å…ˆçº§
            priority = self._get_file_priority(file_path, custom_priorities)

            # ç”Ÿæˆè¾“å‡ºè·¯å¾„
            output_path = f"docs/files/summaries/{file_path}.md"

            task = {
                "id": task_id,
                "type": "file_summary",
                "description": f"ç”Ÿæˆ{file_path}æ–‡ä»¶æ‘˜è¦",
                "phase": "phase_2_files",
                "target_file": file_path,
                "template": "file_summary",
                "output_path": output_path,
                "dependencies": [scan_task_id],
                "priority": priority,
                "estimated_time": "3 minutes",
                "status": "pending",
                "metadata": {
                    "file_type": Path(file_path).suffix,
                    "file_size_category": "unknown"
                }
            }

            tasks.append(task)

        return tasks

    def _generate_phase_3_tasks(self, project_path: str, analysis: Dict[str, Any],
                                phase_2_tasks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ç”Ÿæˆç¬¬ä¸‰é˜¶æ®µä»»åŠ¡ï¼ˆæ¨¡å—å±‚ï¼‰"""
        tasks = []
        modules = analysis.get("identified_modules", [])

        # æ‰€æœ‰æ–‡ä»¶å±‚ä»»åŠ¡ä½œä¸ºä¾èµ–
        file_task_ids = [task["id"] for task in phase_2_tasks]

        # 1. æ¨¡å—æ€»è§ˆä»»åŠ¡
        task_id = f"module_analysis_{int(time.time() * 1000)}"
        tasks.append({
            "id": task_id,
            "type": "module_analysis",
            "description": "ç”Ÿæˆæ¨¡å—æ€»è§ˆå’ŒåŠŸèƒ½åˆ†æ",
            "phase": "phase_3_modules",
            "template": "module_analysis",
            "output_path": "docs/modules/overview.md",
            "dependencies": file_task_ids,
            "priority": "high",
            "estimated_time": "8 minutes",
            "status": "pending",
            "metadata": {
                "modules_count": len(modules),
                "modules_list": modules
            }
        })

        module_analysis_id = task_id

        # 2. æ¨¡å—å…³ç³»ä»»åŠ¡
        task_id = f"module_relations_{int(time.time() * 1000)}"
        tasks.append({
            "id": task_id,
            "type": "module_relations",
            "description": "åˆ†ææ¨¡å—é—´å…³ç³»å’Œä¾èµ–",
            "phase": "phase_3_modules",
            "template": "module_relations",
            "output_path": "docs/modules/module-relations.md",
            "dependencies": [module_analysis_id],
            "priority": "high",
            "estimated_time": "6 minutes",
            "status": "pending",
            "metadata": {}
        })

        # 3. ä¾èµ–å›¾è°±ä»»åŠ¡
        task_id = f"dependency_graph_{int(time.time() * 1000)}"
        tasks.append({
            "id": task_id,
            "type": "dependency_graph",
            "description": "ç”Ÿæˆæ¨¡å—ä¾èµ–å›¾è°±åˆ†æ",
            "phase": "phase_3_modules",
            "template": "dependency_graph",
            "output_path": "docs/modules/dependency-graph.md",
            "dependencies": [module_analysis_id],
            "priority": "normal",
            "estimated_time": "5 minutes",
            "status": "pending",
            "metadata": {}
        })

        # 4. ä¸ºæ¯ä¸ªé‡è¦æ¨¡å—ç”Ÿæˆè¯¦ç»†æ–‡æ¡£
        important_modules = modules[:3]  # æœ€å¤š3ä¸ªé‡è¦æ¨¡å—
        for i, module in enumerate(important_modules):
            module_clean = module.lower().replace(" ", "_").replace("-", "_")

            # æ¨¡å—README
            task_id = f"module_readme_{module_clean}_{int(time.time() * 1000)}"
            tasks.append({
                "id": task_id,
                "type": "module_readme",
                "description": f"ç”Ÿæˆ{module}æ¨¡å—è¯¦ç»†æ–‡æ¡£",
                "phase": "phase_3_modules",
                "target_module": module,
                "template": "module_readme",
                "output_path": f"docs/modules/modules/{module_clean}/README.md",
                "dependencies": [module_analysis_id],
                "priority": "normal",
                "estimated_time": "4 minutes",
                "status": "pending",
                "metadata": {"module_name": module}
            })

            # æ¨¡å—API
            api_task_id = f"module_api_{module_clean}_{int(time.time() * 1000)}"
            tasks.append({
                "id": api_task_id,
                "type": "module_api",
                "description": f"ç”Ÿæˆ{module}æ¨¡å—APIæ–‡æ¡£",
                "phase": "phase_3_modules",
                "target_module": module,
                "template": "module_api",
                "output_path": f"docs/modules/modules/{module_clean}/api.md",
                "dependencies": [task_id],
                "priority": "normal",
                "estimated_time": "3 minutes",
                "status": "pending",
                "metadata": {"module_name": module}
            })

            # æ¨¡å—æµç¨‹
            flow_task_id = f"module_flow_{module_clean}_{int(time.time() * 1000)}"
            tasks.append({
                "id": flow_task_id,
                "type": "module_flow",
                "description": f"ç”Ÿæˆ{module}æ¨¡å—ä¸šåŠ¡æµç¨‹",
                "phase": "phase_3_modules",
                "target_module": module,
                "template": "module_flow",
                "output_path": f"docs/modules/modules/{module_clean}/flow.md",
                "dependencies": [task_id],
                "priority": "low",
                "estimated_time": "3 minutes",
                "status": "pending",
                "metadata": {"module_name": module}
            })

        return tasks

    def _generate_phase_4_tasks(self, project_path: str, analysis: Dict[str, Any],
                                phase_3_tasks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ç”Ÿæˆç¬¬å››é˜¶æ®µä»»åŠ¡ï¼ˆæ¶æ„å±‚ï¼‰"""
        tasks = []

        # æ‰€æœ‰æ¨¡å—å±‚ä»»åŠ¡ä½œä¸ºä¾èµ–
        module_task_ids = [task["id"] for task in phase_3_tasks]

        # 1. æ¶æ„æ¦‚è¿°
        task_id = f"architecture_{int(time.time() * 1000)}"
        tasks.append({
            "id": task_id,
            "type": "architecture",
            "description": "ç”Ÿæˆç³»ç»Ÿæ¶æ„æ¦‚è¿°",
            "phase": "phase_4_architecture",
            "template": "architecture",
            "output_path": "docs/architecture/overview.md",
            "dependencies": module_task_ids,
            "priority": "high",
            "estimated_time": "12 minutes",
            "status": "pending",
            "metadata": {
                "project_type": analysis.get("project_type", "unknown"),
                "complexity": analysis.get("code_complexity", "unknown")
            }
        })

        architecture_id = task_id

        # 2. æŠ€æœ¯æ ˆåˆ†æ
        task_id = f"tech_stack_{int(time.time() * 1000)}"
        tasks.append({
            "id": task_id,
            "type": "tech_stack",
            "description": "åˆ†ææŠ€æœ¯æ ˆå’Œæ¶æ„åŸåˆ™",
            "phase": "phase_4_architecture",
            "template": "tech_stack",
            "output_path": "docs/architecture/tech-stack.md",
            "dependencies": [architecture_id],
            "priority": "high",
            "estimated_time": "10 minutes",
            "status": "pending",
            "metadata": {}
        })

        # 3. æ•°æ®æµè®¾è®¡
        task_id = f"data_flow_{int(time.time() * 1000)}"
        tasks.append({
            "id": task_id,
            "type": "data_flow",
            "description": "è®¾è®¡ç³»ç»Ÿæ•°æ®æµ",
            "phase": "phase_4_architecture",
            "template": "data_flow",
            "output_path": "docs/architecture/data-flow.md",
            "dependencies": [architecture_id],
            "priority": "normal",
            "estimated_time": "8 minutes",
            "status": "pending",
            "metadata": {}
        })

        # 4. ç³»ç»Ÿæ¶æ„å›¾
        task_id = f"system_architecture_{int(time.time() * 1000)}"
        tasks.append({
            "id": task_id,
            "type": "system_architecture",
            "description": "ç»˜åˆ¶ç³»ç»Ÿæ¶æ„å›¾",
            "phase": "phase_4_architecture",
            "template": "system_architecture",
            "output_path": "docs/architecture/diagrams/system-architecture.md",
            "dependencies": [architecture_id],
            "priority": "normal",
            "estimated_time": "6 minutes",
            "status": "pending",
            "metadata": {}
        })

        # 5. ç»„ä»¶å…³ç³»å›¾
        task_id = f"component_diagram_{int(time.time() * 1000)}"
        tasks.append({
            "id": task_id,
            "type": "component_diagram",
            "description": "ç»˜åˆ¶ç»„ä»¶å…³ç³»å›¾",
            "phase": "phase_4_architecture",
            "template": "component_diagram",
            "output_path": "docs/architecture/diagrams/component-diagram.md",
            "dependencies": [architecture_id],
            "priority": "normal",
            "estimated_time": "6 minutes",
            "status": "pending",
            "metadata": {}
        })

        # 6. éƒ¨ç½²æ¶æ„å›¾
        task_id = f"deployment_diagram_{int(time.time() * 1000)}"
        tasks.append({
            "id": task_id,
            "type": "deployment_diagram",
            "description": "è®¾è®¡éƒ¨ç½²æ¶æ„",
            "phase": "phase_4_architecture",
            "template": "deployment_diagram",
            "output_path": "docs/architecture/diagrams/deployment-diagram.md",
            "dependencies": [architecture_id],
            "priority": "low",
            "estimated_time": "5 minutes",
            "status": "pending",
            "metadata": {}
        })

        return tasks

    def _generate_phase_5_tasks(self, project_path: str, analysis: Dict[str, Any],
                                phase_4_tasks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ç”Ÿæˆç¬¬äº”é˜¶æ®µä»»åŠ¡ï¼ˆé¡¹ç›®å±‚ï¼‰"""
        tasks = []

        # æ‰€æœ‰æ¶æ„å±‚ä»»åŠ¡ä½œä¸ºä¾èµ–
        arch_task_ids = [task["id"] for task in phase_4_tasks]

        # åªç”ŸæˆREADME.md
        task_id = f"project_readme_{int(time.time() * 1000)}"
        tasks.append({
            "id": task_id,
            "type": "project_readme",
            "description": "ç”Ÿæˆé¡¹ç›®READMEæ–‡æ¡£",
            "phase": "phase_5_project",
            "template": "project_readme",
            "output_path": "docs/project/README.md",
            "dependencies": arch_task_ids,
            "priority": "high",
            "estimated_time": "10 minutes",
            "status": "pending",
            "metadata": {
                "project_type": analysis.get("project_type", "unknown"),
                "framework": analysis.get("main_framework", "custom"),
                "complexity": analysis.get("code_complexity", "unknown")
            }
        })

        return tasks

    def _get_file_priority(self, file_path: str, custom_priorities: Dict[str, Any] = None) -> str:
        """ç¡®å®šæ–‡ä»¶ä¼˜å…ˆçº§"""
        if custom_priorities and file_path in custom_priorities:
            return custom_priorities[file_path]

        file_lower = file_path.lower()

        # æ£€æŸ¥é«˜ä¼˜å…ˆçº§æ¨¡å¼
        for pattern in self.priority_mapping["high"]:
            if pattern in file_lower:
                return "high"

        # æ£€æŸ¥æ™®é€šä¼˜å…ˆçº§æ¨¡å¼
        for pattern in self.priority_mapping["normal"]:
            if pattern in file_lower:
                return "normal"

        # æ£€æŸ¥ä½ä¼˜å…ˆçº§æ¨¡å¼
        for pattern in self.priority_mapping["low"]:
            if pattern in file_lower:
                return "low"

        return "normal"

    def _build_dependency_graph(self, all_tasks: List[Dict[str, Any]]) -> Dict[str, List[str]]:
        """æ„å»ºä¾èµ–å…³ç³»å›¾"""
        graph = {}

        for task in all_tasks:
            task_id = task["id"]
            dependencies = task.get("dependencies", [])
            graph[task_id] = dependencies

        return graph

    def create_tasks_in_manager(self, task_manager: TaskManager, task_plan: Dict[str, Any]) -> int:
        """åœ¨ä»»åŠ¡ç®¡ç†å™¨ä¸­åˆ›å»ºæ‰€æœ‰ä»»åŠ¡"""
        created_count = 0
        skipped_count = 0
        error_count = 0

        # æŒ‰é˜¶æ®µé¡ºåºåˆ›å»ºä»»åŠ¡
        phases = ["phase_1_scan", "phase_2_files", "phase_3_modules", "phase_4_architecture", "phase_5_project"]

        for phase in phases:
            if phase in task_plan:
                phase_data = task_plan[phase]
                tasks = phase_data.get("tasks", [])
                print(f"å¤„ç†é˜¶æ®µ {phase}: {len(tasks)} ä¸ªä»»åŠ¡")

                for task_data in tasks:
                    # è½¬æ¢ä»»åŠ¡ç±»å‹
                    task_type_str = task_data["type"]
                    try:
                        task_type = TaskType(task_type_str)
                    except ValueError as e:
                        # å¦‚æœæ— æ³•è½¬æ¢ï¼Œè·³è¿‡æ­¤ä»»åŠ¡
                        print(f"è·³è¿‡æ— æ•ˆä»»åŠ¡ç±»å‹: {task_type_str} - {e}")
                        skipped_count += 1
                        continue

                    try:
                        # ğŸ”§ æ ¹æœ¬ä¿®å¤: ä¼ å…¥é¢„å®šä¹‰task_idç¡®ä¿ä¾èµ–å…³ç³»ä¸€è‡´æ€§
                        task_id = task_manager.create_task(
                            task_type=task_type,
                            description=task_data["description"],
                            phase=task_data["phase"],
                            target_file=task_data.get("target_file"),
                            target_module=task_data.get("target_module"),
                            template_name=task_data.get("template"),
                            output_path=task_data.get("output_path"),
                            dependencies=task_data.get("dependencies", []),
                            priority=task_data.get("priority", "normal"),
                            estimated_time=task_data.get("estimated_time"),
                            metadata=task_data.get("metadata", {}),
                            task_id=task_data["id"]  # ä½¿ç”¨é¢„å®šä¹‰çš„task_id
                        )

                        created_count += 1
                        
                    except Exception as e:
                        print(f"åˆ›å»ºä»»åŠ¡å¤±è´¥: {task_data.get('description', 'Unknown')} - {e}")
                        error_count += 1
                        continue

        print(f"ä»»åŠ¡åˆ›å»ºå®Œæˆ - æˆåŠŸ: {created_count}, è·³è¿‡: {skipped_count}, é”™è¯¯: {error_count}")
        return created_count


class TaskInitTool:
    """MCP task_init å·¥å…·ç±»"""

    def __init__(self):
        self.tool_name = "task_init"
        self.description = "åŸºäºé¡¹ç›®åˆ†æç»“æœï¼Œç”Ÿæˆå®Œæ•´çš„é˜¶æ®µæ€§ä»»åŠ¡åˆ—è¡¨"
        self.generator = TaskPlanGenerator()
        self.logger = logging.getLogger('task_init')

    def get_tool_definition(self) -> Dict[str, Any]:
        """è·å–MCPå·¥å…·å®šä¹‰"""
        return {
            "name": self.tool_name,
            "description": self.description,
            "inputSchema": {
                "type": "object",
                "properties": {
                    "project_path": {
                        "type": "string",
                        "description": "é¡¹ç›®è·¯å¾„"
                    },
                    "analysis_result": {
                        "type": "object",
                        "description": "doc_guideçš„åˆ†æç»“æœ",
                        "required": True
                    },
                    "task_granularity": {
                        "type": "string",
                        "enum": ["file", "batch", "module"],
                        "default": "file",
                        "description": "ä»»åŠ¡ç²’åº¦"
                    },
                    "parallel_tasks": {
                        "type": "boolean",
                        "default": False,
                        "description": "æ˜¯å¦æ”¯æŒå¹¶è¡Œä»»åŠ¡"
                    },
                    "custom_priorities": {
                        "type": "object",
                        "description": "è‡ªå®šä¹‰ä¼˜å…ˆçº§è®¾ç½®",
                        "additionalProperties": {"type": "string"}
                    },
                    "create_in_manager": {
                        "type": "boolean",
                        "default": False,
                        "description": "æ˜¯å¦åœ¨ä»»åŠ¡ç®¡ç†å™¨ä¸­åˆ›å»ºä»»åŠ¡"
                    }
                },
                "required": ["project_path", "analysis_result"]
            }
        }

    def execute(self, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œtask_initå·¥å…·"""
        try:
            # å‚æ•°éªŒè¯
            project_path = arguments.get("project_path")
            analysis_result = arguments.get("analysis_result")

            if not project_path or not os.path.exists(project_path):
                return self._error_response("Invalid project path")

            if not analysis_result:
                return self._error_response("Analysis result is required")

            # è·å–å‚æ•°
            task_granularity = arguments.get("task_granularity", "file")
            parallel_tasks = arguments.get("parallel_tasks", False)
            custom_priorities = arguments.get("custom_priorities", {})
            create_in_manager = arguments.get("create_in_manager", False)

            self.logger.info(f"å¼€å§‹ç”Ÿæˆä»»åŠ¡è®¡åˆ’: {project_path}, ç²’åº¦: {task_granularity}")

            # ç”Ÿæˆä»»åŠ¡è®¡åˆ’
            task_plan = self.generator.generate_tasks(
                project_path=project_path,
                analysis_result=analysis_result,
                task_granularity=task_granularity,
                parallel_tasks=parallel_tasks,
                custom_priorities=custom_priorities
            )

            # å¦‚æœéœ€è¦ï¼Œåœ¨ä»»åŠ¡ç®¡ç†å™¨ä¸­åˆ›å»ºä»»åŠ¡
            created_count = 0
            if create_in_manager:
                task_manager = TaskManager(project_path)
                created_count = self.generator.create_tasks_in_manager(task_manager, task_plan)
                self.logger.info(f"ä»»åŠ¡å·²åˆ›å»ºåœ¨ç®¡ç†å™¨ä¸­: {created_count} ä¸ª")

            self.logger.info(f"ä»»åŠ¡è®¡åˆ’ç”Ÿæˆå®Œæˆ - æ€»ä»»åŠ¡: {task_plan['task_plan']['total_tasks']}, "
                             f"é˜¶æ®µ: {task_plan['task_plan']['total_phases']}")

            response_data = task_plan.copy()
            if create_in_manager:
                response_data["manager_info"] = {
                    "tasks_created": created_count,
                    "creation_successful": True
                }

            return self._success_response(response_data)

        except Exception as e:
            self.logger.error(f"ä»»åŠ¡è®¡åˆ’ç”Ÿæˆå¤±è´¥: {str(e)}", exc_info=e)
            return self._error_response(f"Task initialization failed: {str(e)}")

    def _success_response(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """æˆåŠŸå“åº”"""
        return {
            "success": True,
            "tool": self.tool_name,
            "data": data
        }

    def _error_response(self, message: str) -> Dict[str, Any]:
        """é”™è¯¯å“åº”"""
        return {
            "success": False,
            "tool": self.tool_name,
            "error": message
        }


def create_mcp_tool() -> TaskInitTool:
    """åˆ›å»ºMCPå·¥å…·å®ä¾‹"""
    return TaskInitTool()


# å‘½ä»¤è¡Œæ¥å£ï¼Œç”¨äºæµ‹è¯•
def main():
    """å‘½ä»¤è¡Œæµ‹è¯•æ¥å£"""
    import argparse

    parser = argparse.ArgumentParser(description="MCP task_init tool")
    parser.add_argument("project_path", help="Project path")
    parser.add_argument("--analysis-file", required=True,
                        help="JSON file with analysis result from doc_guide")
    parser.add_argument("--granularity", choices=["file", "batch", "module"],
                        default="file", help="Task granularity")
    parser.add_argument("--create-tasks", action="store_true",
                        help="Create tasks in task manager")

    args = parser.parse_args()

    # è¯»å–åˆ†æç»“æœ
    try:
        with open(args.analysis_file, 'r', encoding='utf-8') as f:
            analysis_result = json.load(f)
    except Exception as e:
        print(f"Error reading analysis file: {e}")
        return

    # æ„å»ºå‚æ•°
    arguments = {
        "project_path": args.project_path,
        "analysis_result": analysis_result,
        "task_granularity": args.granularity,
        "create_in_manager": args.create_tasks
    }

    # æ‰§è¡Œå·¥å…·
    tool = create_mcp_tool()
    result = tool.execute(arguments)

    # è¾“å‡ºç»“æœ
    print(json.dumps(result, indent=2, ensure_ascii=False))


if __name__ == "__main__":
    main()
